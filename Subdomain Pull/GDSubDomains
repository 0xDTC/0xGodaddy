#!/bin/bash
# Usage: ./GDSubDomains.sh [-l] [-g] [-c]
#   -l    Enable logging (default: logging disabled)
#   -g    Run GoDaddy asset fetch only
#   -c    Run Cloudflare asset fetch only
#         If neither -g nor -c is specified, both services will be queried

#####################
# Option Parsing    #
#####################
LOG_ENABLED=false
RUN_GODADDY=false
RUN_CLOUDFLARE=false

while getopts ":lgc" opt; do
  case ${opt} in
    l )
      LOG_ENABLED=true
      ;;
    g )
      RUN_GODADDY=true
      ;;
    c )
      RUN_CLOUDFLARE=true
      ;;
    \? )
      echo "Usage: $0 [-l] [-g] [-c]" >&2
      echo "  -l  Enable logging" >&2
      echo "  -g  Run GoDaddy asset fetch only" >&2
      echo "  -c  Run Cloudflare asset fetch only" >&2
      echo "  If neither -g nor -c is specified, both will run" >&2
      exit 1
      ;;
  esac
done

# If neither service flag is specified, run both
if [[ "$RUN_GODADDY" == "false" && "$RUN_CLOUDFLARE" == "false" ]]; then
  RUN_GODADDY=true
  RUN_CLOUDFLARE=true
fi

# Set up logging
if $LOG_ENABLED; then
    log_file="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)/script_debug.log"
else
    log_file="/dev/null"
fi

#####################
# Load Secrets      #
#####################
if [[ ! -f ../secret.txt ]]; then
    echo "Error: Secrets file (../secret.txt) not found. Please create it with required credentials."
    exit 1
fi
source ../secret.txt

if [[ -z "$GODADDY_API_KEY" || -z "$GODADDY_API_SECRET" || -z "$CLOUDFLARE_API_TOKEN" ]]; then
    echo "Error: Missing GODADDY_API_KEY, GODADDY_API_SECRET, or CLOUDFLARE_API_TOKEN in secret.txt."
    exit 1
fi

#####################
# Variable Setup    #
#####################
PAGE_SIZE=1000
script_dir="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
today_date=$(date +%Y-%m-%d)

# Output files
godaddy_file="$script_dir/godaddy_assets.json"
cloudflare_file="$script_dir/cloudflare_assets.json"
merged_file="$script_dir/org_assets.json"
markdown_file="$script_dir/Org-Assets.md"
html_file="$script_dir/Org-Assets.html"
assets_history_file="$script_dir/assets_history.json"
# Cloudflare zone cache file
cloudflare_zones_cache="$script_dir/cloudflare_zones_cache.json"

# Initialize logs
echo "Script Execution Started: $(date)" > "$log_file"

#####################
# Helper Functions  #
#####################
log_message() {
    echo "$1" | tee -a "$log_file"
}

# Ensure history file exists and is valid JSON
if [[ ! -f "$assets_history_file" ]] || [[ ! -s "$assets_history_file" ]]; then
    log_message "Creating new assets history file..."
    echo "[]" > "$assets_history_file"
fi

# Validate the history file
if ! jq empty "$assets_history_file" 2>/dev/null; then
    log_message "History file was invalid JSON, resetting it..."
    echo "[]" > "$assets_history_file"
fi

#####################
# API Connectivity   #
#####################
check_api_connectivity() {
    log_message "Checking API connectivity..."
    
    # Check GoDaddy API
    log_message "Checking GoDaddy API connectivity..."
    local godaddy_check
    godaddy_check=$(curl -s -X GET \
        -H "Authorization: sso-key $GODADDY_API_KEY:$GODADDY_API_SECRET" \
        -H "Accept: application/json" \
        "https://api.godaddy.com/v1/domains/available?domain=test-connectivity-check.com")
    
    if [[ $? -ne 0 || -z "$godaddy_check" ]]; then
        log_message "Error: Failed to connect to GoDaddy API. Check your network connection."
        return 1
    fi
    
    if ! echo "$godaddy_check" | jq empty &>/dev/null; then
        log_message "Error: Invalid response from GoDaddy API. Check credentials."
        return 1
    fi
    
    # Check for quota issues
    if echo "$godaddy_check" | grep -q "QUOTA_EXCEEDED"; then
        log_message "Warning: GoDaddy API quota already exceeded before script execution."
        log_message "  - Error: $(echo "$godaddy_check" | grep -o 'QUOTA_EXCEEDED.*')"
    else
        log_message "GoDaddy API connection successful."
    fi
    
    # Check Cloudflare API
    log_message "Checking Cloudflare API connectivity..."
    local cloudflare_check
    cloudflare_check=$(curl -s -X GET "https://api.cloudflare.com/client/v4/user/tokens/verify" \
        -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN")
    
    if [[ $? -ne 0 || -z "$cloudflare_check" ]]; then
        log_message "Error: Failed to connect to Cloudflare API. Check your network connection."
        return 1
    fi
    
    if ! echo "$cloudflare_check" | jq -e '.success' &>/dev/null; then
        log_message "Error: Invalid or unauthorized Cloudflare API token. Check credentials."
        return 1
    fi
    
    log_message "Cloudflare API connection successful."
    
    return 0
}

# Ensure a file is a valid JSON array
ensure_json_array() {
    local file="$1"
    if [[ ! -s "$file" ]]; then
        echo "[]" > "$file"
        return
    fi
    if ! jq empty "$file" 2>/dev/null; then
        log_message "Warning: $file is invalid JSON; resetting to []."
        echo "[]" > "$file"
        return
    fi
    if ! jq -e 'if type=="array" then true else false end' "$file" &>/dev/null; then
        log_message "Warning: $file is JSON but not an array; converting to []."
        echo "[]" > "$file"
    fi
}

# Merge two JSON array files
merge_json_files() {
    local in1="$1"
    local in2="$2"
    local out="$3"
    ensure_json_array "$in1"
    ensure_json_array "$in2"
    if ! jq -s '.[0] + .[1]' "$in1" "$in2" > "${out}.tmp" 2>/dev/null; then
        log_message "Warning: merging $in1 and $in2 failed, defaulting to []."
        echo "[]" > "$out"
    else
        mv "${out}.tmp" "$out"
        ensure_json_array "$out"
    fi
}

#####################
# API Functions     #
#####################

# Format DNS records from GoDaddy response
format_godaddy_records() {
    local response="$1"
    local domain="$2"
    local today="$3"
    
    if [[ -z "$response" ]]; then
        echo "[]"
        return
    fi
    
    # Check if response is valid JSON
    if ! echo "$response" | jq empty 2>/dev/null; then
        echo "[]"
        return
    fi
    
    # Transform the records into our desired format
    echo "$response" | jq --arg domain "$domain" --arg today "$today" '
        if type == "array" then
            map({
                name: (.name // "@"),
                type: (.type // "UNKNOWN"),
                data: (.data // .value // "N/A"),
                domain: $domain,
                source: "GoDaddy",
                discovery_date: $today
            })
        else
            []
        end'
}

# Format DNS records from Cloudflare response
format_cloudflare_records() {
    local response="$1"
    local domain="$2"
    local today="$3"
    
    if [[ -z "$response" ]]; then
        echo "[]"
        return
    fi
    
    # Check if response is valid JSON
    if ! echo "$response" | jq empty 2>/dev/null; then
        echo "[]"
        return
    fi
    
    # Transform the records into our desired format
    echo "$response" | jq --arg domain "$domain" --arg today "$today" '
        if (.result != null and (.result | type) == "array") then
            .result | map({
                name: (.name // "@"),
                type: (.type // "UNKNOWN"),
                data: (.content // "N/A"),
                domain: $domain,
                source: "Cloudflare",
                discovery_date: $today
            })
        else
            []
        end'
}

# Fetch domains and subdomains from GoDaddy
fetch_godaddy_assets() {
    log_message "Fetching assets from GoDaddy..."
    local domains=()
    local domains_json="[]"
    local quota_exceeded=false
    local quota_error_message=""
    
    # Use the approach from GDomains script that's successfully listing domains
    local marker=""
    local page=1
    local max_pages=10  # Limit to avoid infinite loops
    
    log_message "Retrieving domains from GoDaddy API (paginated)..."
    
    while [[ $page -le $max_pages ]]; do
        log_message "Fetching page $page of domains..."
        local response
        response=$(curl -s -X GET \
            -H "Authorization: sso-key $GODADDY_API_KEY:$GODADDY_API_SECRET" \
            -H "Accept: application/json" \
            "https://api.godaddy.com/v1/domains?statuses=ACTIVE&limit=$PAGE_SIZE&marker=$marker")
        
        # Check if we hit the API quota limit
        if echo "$response" | grep -q "QUOTA_EXCEEDED"; then
            quota_error_message=$(echo "$response" | grep -o 'QUOTA_EXCEEDED.*' | tr -d '"{},' | sed 's/:/: /g')
            log_message "Warning: GoDaddy API quota exceeded. Some functionality will be limited."
            log_message "  - Error: $quota_error_message"
            quota_exceeded=true
            break
        elif [[ $? -eq 0 && -n "$response" ]] && echo "$response" | jq empty &>/dev/null; then
            # Check response format and handle differently based on structure
            local response_type
            response_type=$(echo "$response" | jq -r 'type')
            
            if [[ "$response_type" == "array" ]]; then
                # Extract domain names and add to array
                local count=0
                count=$(echo "$response" | jq 'length')
                
                if [[ $count -gt 0 ]]; then
                    while read -r domain; do
                        domains+=("$domain")
                    done < <(echo "$response" | jq -r '.[].domain')
                    
                    log_message "Retrieved $count domains from GoDaddy API (page $page)"
                    
                    # If we got less than the page size, we've reached the end
                    if [[ $count -lt $PAGE_SIZE ]]; then
                        break
                    fi
                    
                    # Update marker for next page
                    marker=$(echo "$response" | jq -r '.[-1].domain')
                    ((page++))
                else
                    log_message "No domains found on page $page, ending pagination"
                    break
                fi
            elif [[ "$response_type" == "object" ]]; then
                # It's an object with domain info - extract domain name if available
                if echo "$response" | jq -e '.domain' &>/dev/null; then
                    local domain=$(echo "$response" | jq -r '.domain')
                    domains+=("$domain")
                    log_message "Retrieved single domain from GoDaddy API: $domain"
                    break
                fi
            else
                log_message "Unexpected response type from GoDaddy API: $response_type"
                break
            fi
        else
            log_message "Warning: Could not retrieve domains list from GoDaddy API directly"
            break
        fi
    done
    
    # If no domains found via the domains API, try to use the domains from the Domain Pull directory
    if [[ ${#domains[@]} -eq 0 ]]; then
        log_message "No domains found via API, checking for domains in Domain Pull directory..."
        local domain_pull_dir="$(cd "$script_dir" && cd "../Domain Pull" && pwd)"
        local domains_md="$domain_pull_dir/GDdomain.md"
        
        if [[ -f "$domains_md" ]]; then
            log_message "Using domains from GDdomain.md file in Domain Pull directory..."
            # Extracting all active domains without the 1000 line limit
            local active_domains=$(awk '/Domains and Their Statuses/{flag=1; next} flag && /ACTIVE/ {print $1}' "$domains_md" | awk -F'|' '{print $1}' | sed 's/ *$//' | sed 's/^ *//')
            
            if [[ -n "$active_domains" ]]; then
                while IFS= read -r domain; do
                    if [[ -n "$domain" && "$domain" != "Domain" && "$domain" != "---"* ]]; then
                        domains+=("$domain")
                    fi
                done <<< "$active_domains"
                log_message "Found $(echo "${domains[@]}" | wc -w) domains from Domain Pull directory"
            fi
        else
            log_message "Domains file in Domain Pull directory not found"
        fi
    fi
    
    # If still no domains found, use a limited number of domains from the fallback list to avoid excessive API calls
    if [[ ${#domains[@]} -eq 0 ]]; then
        log_message "No domains found from any source, using fallback domain list..."
        
        # Try to run the Domain Pull script to generate an updated list
        log_message "Attempting to run the Domain Pull script to get fresh domain list..."
        local domain_pull_script="$(cd "$script_dir" && cd "../Domain Pull" && pwd)/GDomains"
        
        if [[ -f "$domain_pull_script" && -x "$domain_pull_script" ]]; then
            log_message "Running Domain Pull script to generate fresh domain list..."
            (cd "$(dirname "$domain_pull_script")" && "$domain_pull_script" > /dev/null)
            
            # Now try again to read domains from the updated file
            if [[ -f "$domains_md" ]]; then
                log_message "Using domains from newly generated GDdomain.md file..."
                # Extracting all active domains without the 1000 line limit
                local active_domains=$(awk '/Domains and Their Statuses/{flag=1; next} flag && /ACTIVE/ {print $1}' "$domains_md" | awk -F'|' '{print $1}' | sed 's/ *$//' | sed 's/^ *//')
                
                if [[ -n "$active_domains" ]]; then
                    domains=()
                    while IFS= read -r domain; do
                        if [[ -n "$domain" && "$domain" != "Domain" && "$domain" != "---"* ]]; then
                            domains+=("$domain")
                        fi
                    done <<< "$active_domains"
                    log_message "Found $(echo "${domains[@]}" | wc -w) domains from updated Domain Pull directory"
                fi
            fi
        else
            log_message "Domain Pull script not found or not executable"
        fi
        
        # If still no domains, use the hardcoded fallback list
        if [[ ${#domains[@]} -eq 0 ]]; then
            log_message "Still no domains found, using hardcoded fallback list"
            # Use a limited number of domains to avoid excessive API calls
            read -r -d '' IMPORTANT_DOMAINS << EOL
100bestfonts.com
linotype.com
typography.com
fontshop.com
EOL
            
            while IFS= read -r domain; do
                if [[ -n "$domain" ]]; then
                    domains+=("$domain")
                fi
            done <<< "$IMPORTANT_DOMAINS"
        fi
    fi
    
    # Option to limit domains processed - removed limit to process all domains
    # If you want to re-enable the limit, uncomment these lines:
    # local domain_limit=20
    # if [[ ${#domains[@]} -gt $domain_limit ]]; then
    #     log_message "Limiting domains to $domain_limit to avoid excessive API calls"
    #     domains=(${domains[@]:0:$domain_limit})
    # fi
    
    local total_domains=${#domains[@]}
    log_message "Found $total_domains domains in GoDaddy"
    
    if [[ $total_domains -eq 0 ]]; then
        log_message "No domains found. Check GoDaddy API credentials."
        echo "[]" > "$godaddy_file"
        return
    fi
    
    # Log all domains we're processing
    log_message "Domains to process: ${domains[*]}"
    
    # Now get DNS records for each domain
    local godaddy_assets="[]"
    local domain_count=0
    
    # If the quota is already exceeded, don't even try to fetch DNS records
    if [[ "$quota_exceeded" == "true" ]]; then
        log_message "Skipping GoDaddy DNS record fetching due to API quota restrictions."
        log_message "WARNING: No GoDaddy assets will be available in the final output."
        if [[ -n "$quota_error_message" ]]; then
            log_message "Quota error details: $quota_error_message"
        fi
        log_message "Consider waiting until the API quota resets, or contacting GoDaddy to increase your quota limit."
        echo "$godaddy_assets" > "$godaddy_file"
        return
    fi
    
    for domain in "${domains[@]}"; do
        ((domain_count++))
        echo "Processing domain $domain_count/$total_domains: $domain"
        log_message "Fetching DNS records for $domain ($domain_count of $total_domains)..."
        
        # Add a small delay between domains to avoid rate limiting
        if [[ $domain_count -gt 1 ]]; then
            sleep 1
        fi
        
        # Implement pagination for DNS records
        local all_dns_records='[]'
        local page=1
        local has_more=true
        
        while $has_more; do
            # Fetch DNS records with pagination
            local dns_records_response
            dns_records_response=$(curl -s -X GET \
                -H "Authorization: sso-key $GODADDY_API_KEY:$GODADDY_API_SECRET" \
                -H "Accept: application/json" \
                "https://api.godaddy.com/v1/domains/$domain/records?offset=$(( (page-1) * 100 ))&limit=100")
            
            # Check if we hit the API quota limit
            if echo "$dns_records_response" | grep -q "QUOTA_EXCEEDED"; then
                quota_error_message=$(echo "$dns_records_response" | grep -o 'QUOTA_EXCEEDED.*' | tr -d '"{},' | sed 's/:/: /g')
                log_message "Warning: GoDaddy API quota exceeded when fetching records for $domain."
                log_message "  - Error: $quota_error_message"
                log_message "No more DNS records can be fetched until the quota resets."
                echo "ERROR: GoDaddy API quota exceeded when fetching records for $domain."
                quota_exceeded=true
                break 2  # Break out of both loops
            elif echo "$dns_records_response" | grep -q "TOO_MANY_REQUESTS"; then
                log_message "Warning: Rate limit exceeded (TOO_MANY_REQUESTS) for $domain. Waiting and trying again."
                echo "Rate limit hit for $domain. Waiting 30 seconds before continuing..."
                sleep 30  # Wait 30 seconds before trying again
                continue  # Try the same page again
            fi
            
            # First check if response is a valid array (success case)
            if echo "$dns_records_response" | jq -e 'type == "array"' &>/dev/null; then
                # This is a valid array response, process it
                :  # No-op, continue with processing below
            else
                # This might be an error response, check for error code
                local error_code
                error_code=$(echo "$dns_records_response" | jq -r '.code // empty')
                if [[ -n "$error_code" ]]; then
                    local error_message
                    error_message=$(echo "$dns_records_response" | jq -r '.message // "Unknown error"')
                    
                    if [[ "$error_code" == "UNKNOWN_DOMAIN" ]]; then
                        log_message "Domain $domain not found in GoDaddy"
                        echo "- Domain $domain not found in GoDaddy"
                        break  # Move to next domain
                    else
                        log_message "Error: Failed to fetch DNS records for domain $domain: $error_code - $error_message"
                        echo "✗ Error ($error_code) fetching DNS records for $domain"
                        break  # Move to next domain
                    fi
                else
                    # Neither a valid array nor a recognized error response
                    log_message "Warning: Invalid response format for $domain"
                    echo "✗ Invalid response format for $domain"
                    break  # Move to next domain
                fi
            fi
            
            # Check if we got any records on this page
            local page_count
            page_count=$(echo "$dns_records_response" | jq 'length')
            
            if [[ $page_count -eq 0 ]]; then
                has_more=false
            else
                # Merge with existing records
                echo "$all_dns_records" > "$script_dir/tmp_all_dns.json"
                echo "$dns_records_response" > "$script_dir/tmp_page_dns.json"
                jq -s 'add' "$script_dir/tmp_all_dns.json" "$script_dir/tmp_page_dns.json" > "$script_dir/tmp_merged_dns.json"
                all_dns_records=$(cat "$script_dir/tmp_merged_dns.json")
                rm -f "$script_dir/tmp_all_dns.json" "$script_dir/tmp_page_dns.json" "$script_dir/tmp_merged_dns.json"
                
                # If we got less than 100 records, we're done with pagination
                if [[ $page_count -lt 100 ]]; then
                    has_more=false
                else
                    # Add small delay to avoid rate limiting
                    sleep 0.5
                    ((page++))
                fi
            fi
        done
        
        # Process all the records for this domain
        local record_count
        record_count=$(echo "$all_dns_records" | jq 'length')
        
        if [[ $record_count -gt 0 ]]; then
            # Format the records for our assets format
            local formatted
            formatted=$(format_godaddy_records "$all_dns_records" "$domain" "$today_date")
            
            if [[ "$formatted" != "[]" ]]; then
                # Create temp files with proper JSON arrays
                echo "$godaddy_assets" > "$script_dir/tmp_assets.json"
                echo "$formatted" > "$script_dir/tmp_formatted.json"
                
                # Ensure both files are valid JSON arrays
                ensure_json_array "$script_dir/tmp_assets.json"
                ensure_json_array "$script_dir/tmp_formatted.json"
                
                # Properly merge the JSON arrays
                jq -s 'add' "$script_dir/tmp_assets.json" "$script_dir/tmp_formatted.json" > "$script_dir/tmp_merged.json"
                
                # Verify the merged file is a valid JSON array
                if jq empty "$script_dir/tmp_merged.json" 2>/dev/null; then
                    godaddy_assets=$(cat "$script_dir/tmp_merged.json")
                    record_count=$(echo "$formatted" | jq 'length')
                    log_message "Successfully processed $record_count DNS records for $domain"
                    echo "✓ Successfully processed $record_count DNS records for $domain"
                else
                    log_message "Warning: Error merging DNS records for $domain. Using original records."
                    echo "✗ Error merging DNS records for $domain"
                fi
                
                # Clean up temp files
                rm -f "$script_dir/tmp_assets.json" "$script_dir/tmp_formatted.json" "$script_dir/tmp_merged.json"
            else
                log_message "No valid DNS records found for $domain"
                echo "- No DNS records found for $domain"
            fi
        elif echo "$all_dns_records" | jq -e 'type == "object" and has("code")' &>/dev/null; then
            local error_code=$(echo "$all_dns_records" | jq -r '.code')
            if [[ "$error_code" == "UNKNOWN_DOMAIN" ]]; then
                log_message "Domain $domain not found in GoDaddy"
                echo "- Domain $domain not found in GoDaddy"
            else
                log_message "Warning: Error fetching DNS records for $domain: $error_code"
                echo "✗ Error ($error_code) fetching DNS records for $domain"
            fi
        else
            log_message "Warning: Empty response when fetching DNS records for $domain"
            echo "✗ Empty response for $domain"
        fi
    done

    # Save GoDaddy assets
    echo "$godaddy_assets" > "$godaddy_file"
    
    # Final message about quota if needed
    if [[ "$quota_exceeded" == "true" ]]; then
        log_message "WARNING: GoDaddy API quota has been exceeded."
        if [[ -n "$quota_error_message" ]]; then
            log_message "Quota error details: $quota_error_message"
        fi
        log_message "The output will only contain partial GoDaddy assets. GoDaddy assets: $(echo "$godaddy_assets" | jq 'length')"
    else
        log_message "Saved $(echo "$godaddy_assets" | jq 'length') GoDaddy assets to $godaddy_file"
    fi
}

# Fetch assets from Cloudflare
fetch_cloudflare_assets() {
    log_message "Fetching assets from Cloudflare..."
    
    # Initialize variables
    local cloudflare_assets="[]"
    local zones_json="[]"
    local cache_valid=false
    local cache_age_days=999
    
    # Check if the Cloudflare zone cache exists and how old it is
    if [[ -f "$cloudflare_zones_cache" ]] && jq empty "$cloudflare_zones_cache" &>/dev/null; then
        # Check if the cache file is less than 7 days old
        local cache_date
        # Handle different stat command formats for different OS environments
        if [[ "$(uname)" == "Darwin" ]]; then
            # macOS
            cache_date=$(stat -f "%m" "$cloudflare_zones_cache" 2>/dev/null || echo 0)
        else
            # Linux and other systems
            cache_date=$(stat -c "%Y" "$cloudflare_zones_cache" 2>/dev/null || echo 0)
        fi
        
        local current_date=$(date +%s)
        cache_age_days=$(( (current_date - cache_date) / 86400 ))
        
        if [[ $cache_age_days -lt 7 ]]; then
            cache_valid=true
            log_message "Using cached Cloudflare zones ($cache_age_days days old)"
        else
            log_message "Cloudflare zones cache expired ($cache_age_days days old), will refresh"
        fi
    else
        log_message "No valid Cloudflare zones cache found, will create new one"
    fi
    
    # Fetch zones if needed
    if [[ "$cache_valid" == "true" ]]; then
        zones_json=$(cat "$cloudflare_zones_cache")
        local zone_count=$(echo "$zones_json" | jq 'length')
        log_message "Using $zone_count cached Cloudflare zones from cache ($cache_age_days days old)"
        echo "Using $zone_count cached Cloudflare zones from cache ($cache_age_days days old)"
    else
        # First verify API connection before fetching all zones
        local test_response
        test_response=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones?page=1&per_page=1" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
            -H "Content-Type: application/json")
            
        if [[ -z "$test_response" ]] || ! echo "$test_response" | jq -e '.success' &>/dev/null; then
            local error_msg="Unknown error"
            if [[ -n "$test_response" ]]; then
                error_msg=$(echo "$test_response" | jq -r '.errors[0].message // "Unknown error"')
            fi
            
            log_message "Error: Failed to connect to Cloudflare API: $error_msg"
            echo "Error: Failed to connect to Cloudflare API: $error_msg"
            
            # If cache exists but is old, still use it as fallback
            if [[ -f "$cloudflare_zones_cache" ]] && jq empty "$cloudflare_zones_cache" &>/dev/null; then
                log_message "Using existing cache as fallback despite age"
                echo "Using existing cache as fallback despite age"
                zones_json=$(cat "$cloudflare_zones_cache")
            else
                log_message "No usable cache available, cannot retrieve Cloudflare assets"
                echo "No usable cache available, cannot retrieve Cloudflare assets"
                echo "[]" > "$cloudflare_file"
                return
            fi
        else
            log_message "Fetching Cloudflare zones (cache expired or invalid)..."
            echo "Fetching Cloudflare zones (cache expired or invalid)..."
            local page=1
            local has_more=true
            
            while [[ "$has_more" == "true" ]]; do
                local zones_response
                zones_response=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones?page=$page&per_page=50" \
                    -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
                    -H "Content-Type: application/json")
                
                if [[ $? -ne 0 || -z "$zones_response" ]]; then
                    log_message "Error: Failed to fetch Cloudflare zones on page $page"
                    echo "Error: Failed to fetch Cloudflare zones on page $page"
                    break
                fi
                
                if ! echo "$zones_response" | jq -e '.success' &>/dev/null; then
                    error_msg=$(echo "$zones_response" | jq -r '.errors[0].message // "Unknown error"')
                    log_message "Error: Cloudflare API error: $error_msg"
                    echo "Error: Cloudflare API error: $error_msg"
                    break
                fi
                
                local page_zones=$(echo "$zones_response" | jq '.result')
                local page_zone_count=$(echo "$page_zones" | jq 'length')
                
                if [[ $page_zone_count -eq 0 ]]; then
                    has_more=false
                else
                    # Temporary files to help with merging
                    printf '%s\n' "$zones_json" > "$script_dir/tmp_zones.json"
                    printf '%s\n' "$page_zones" > "$script_dir/tmp_page_zones.json"
                    
                    # Merge existing zones with new ones
                    jq -s 'add' "$script_dir/tmp_zones.json" "$script_dir/tmp_page_zones.json" > "$script_dir/tmp_merged_zones.json"
                    zones_json=$(cat "$script_dir/tmp_merged_zones.json")
                    
                    # Clean up temp files
                    rm -f "$script_dir/tmp_zones.json" "$script_dir/tmp_page_zones.json" "$script_dir/tmp_merged_zones.json"
                    
                    # Increment page and check if we should continue
                    ((page++))
                    has_more=$(echo "$zones_response" | jq -r '.result_info.has_more')
                    
                    log_message "Fetched $page_zone_count Cloudflare zones (page $((page-1)))"
                    echo "Fetched $page_zone_count Cloudflare zones (page $((page-1)))"
                fi
            done
            
            # Cache the zones for future use if we successfully fetched some
            local total_zone_count=$(echo "$zones_json" | jq 'length')
            if [[ $total_zone_count -gt 0 ]]; then
                echo "$zones_json" > "$cloudflare_zones_cache"
                log_message "Cached $total_zone_count Cloudflare zones for future use"
                echo "Cached $total_zone_count Cloudflare zones for future use"
            fi
        fi
    fi
    
    # At this point we should have zones_json populated either from cache or fresh API calls
    local zone_count=$(echo "$zones_json" | jq 'length')
    if [[ $zone_count -eq 0 ]]; then
        log_message "No Cloudflare zones found. Check API token permissions."
        echo "No Cloudflare zones found. Check API token permissions."
        echo "[]" > "$cloudflare_file"
        return
    fi
    
    # Process each zone to get DNS records
    local cloudflare_assets="[]"
    local zone_index=0
    local total_zones=$(echo "$zones_json" | jq 'length')
    local processed_records=0
    
    echo "Processing $total_zones Cloudflare zones..."
    
    # Process each zone safely
    local zone_ids=()
    local zone_names=()
    
    # First, extract all valid zone IDs and names into arrays
    local valid_zones=0
    while read -r zone_id zone_name; do
        if [[ -n "$zone_id" && "$zone_id" != "null" ]]; then
            zone_ids[$valid_zones]="$zone_id"
            zone_names[$valid_zones]="$zone_name"
            ((valid_zones++))
        else
            log_message "Skipping zone with invalid ID: $zone_name"
        fi
    done < <(echo "$zones_json" | jq -r '.[] | select(.id != null and .id != "") | [.id, .name] | @tsv')
    
    log_message "Found $valid_zones valid Cloudflare zones to process"
    
    # Now process the zones using the arrays
    for ((i=0; i<${#zone_ids[@]}; i++)); do
        ((zone_index++))
        
        local zone_id="${zone_ids[i]}"
        local zone_name="${zone_names[i]}"
        
        log_message "Fetching DNS records for zone $zone_name ($zone_id)"
        
        # Show progress every 10 zones processed to avoid excessive terminal output
        if (( zone_index % 10 == 0 )); then
            echo "Progress: Processing zone $zone_index of $total_zones ($zone_name)"
        fi
        
        # Add small delay to avoid rate limiting
        if [[ $zone_index -gt 1 ]]; then
            sleep 0.5
        fi
        
        # Initialize variables for pagination
        local page=1
        local all_dns_records='[]'
        local total_record_count=0
        local has_more=true
        
        while $has_more; do
            log_message "Fetching DNS records page $page for zone $zone_name..."
            
            local dns_response
            dns_response=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones/$zone_id/dns_records?per_page=100&page=$page" \
                -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
                -H "Content-Type: application/json")
            
            if [[ $? -ne 0 || -z "$dns_response" ]]; then
                log_message "Error: Failed to fetch DNS records for zone $zone_name on page $page"
                break
            fi
            
            if ! echo "$dns_response" | jq -e '.success' &>/dev/null; then
                error_msg=$(echo "$dns_response" | jq -r '.errors[0].message // "Unknown error"')
                log_message "Error: Cloudflare API error for zone $zone_name on page $page: $error_msg"
                break
            fi
            
            local page_dns_records=$(echo "$dns_response" | jq '.result')
            local page_record_count=$(echo "$page_dns_records" | jq 'length')
            
            if [[ $page_record_count -eq 0 ]]; then
                # No more records to fetch
                has_more=false
            else
                # Merge with the accumulated records
                printf '%s\n' "$all_dns_records" > "$script_dir/tmp_all_cf_dns.json"
                printf '%s\n' "$page_dns_records" > "$script_dir/tmp_page_cf_dns.json"
                jq -s 'add' "$script_dir/tmp_all_cf_dns.json" "$script_dir/tmp_page_cf_dns.json" > "$script_dir/tmp_merged_cf_dns.json"
                all_dns_records=$(cat "$script_dir/tmp_merged_cf_dns.json")
                rm -f "$script_dir/tmp_all_cf_dns.json" "$script_dir/tmp_page_cf_dns.json" "$script_dir/tmp_merged_cf_dns.json"
                
                total_record_count=$((total_record_count + page_record_count))
                
                # Check if we should continue pagination
                local total_count=$(echo "$dns_response" | jq -r '.result_info.total_count // 0')
                local count=$(echo "$dns_response" | jq -r '.result_info.count // 0')
                local per_page=$(echo "$dns_response" | jq -r '.result_info.per_page // 100')
                
                if [[ $count -lt $per_page ]] || [[ $total_count -le $((page * per_page)) ]]; then
                    has_more=false
                else
                    ((page++))
                    # Small delay to avoid hitting rate limits
                    sleep 0.5
                fi
            fi
        done
        
        local dns_records="$all_dns_records"
        local record_count=$total_record_count
        processed_records=$((processed_records + record_count))
        
        if [[ $record_count -gt 0 ]]; then
            # Format the records for our assets format
            # Properly handle each record individually to ensure valid JSON
            local tmp_formatted_file="$script_dir/tmp_cf_formatted.json"
            echo "[" > "$tmp_formatted_file"
            
            local first_item=true
            echo "$dns_records" | jq -c '.[]' | while read -r record; do
                local record_name=$(echo "$record" | jq -r '.name // "@"')
                local record_type=$(echo "$record" | jq -r '.type')
                local record_content=$(echo "$record" | jq -r '.content // "N/A"')
                
                # Create a valid JSON object for this record
                local record_json
                record_json=$(jq -n --arg name "$record_name" \
                               --arg type "$record_type" \
                               --arg data "$record_content" \
                               --arg domain "$zone_name" \
                               --arg source "Cloudflare" \
                               --arg date "$today_date" \
                               '{"name": $name, "type": $type, "data": $data, "domain": $domain, "source": $source, "discovery_date": $date}')
                
                # Add comma if not the first item
                if $first_item; then
                    first_item=false
                else
                    echo "," >> "$tmp_formatted_file"
                fi
                
                # Append to the formatted file
                printf '%s\n' "$record_json" >> "$tmp_formatted_file"
            done
            
            # Close the JSON array
            echo "]" >> "$tmp_formatted_file"
            
            # Ensure it's a valid JSON array
            if ! jq empty "$tmp_formatted_file" 2>/dev/null; then
                log_message "Warning: Invalid JSON created for zone $zone_name, using empty array"
                echo "[]" > "$tmp_formatted_file"
            fi
            
            # Merge with existing assets
            echo "$cloudflare_assets" > "$script_dir/tmp_cf_assets.json"
            
            ensure_json_array "$script_dir/tmp_cf_assets.json"
            ensure_json_array "$script_dir/tmp_cf_formatted.json"
            
            jq -s 'add' "$script_dir/tmp_cf_assets.json" "$script_dir/tmp_cf_formatted.json" > "$script_dir/tmp_cf_merged.json"
            cloudflare_assets=$(cat "$script_dir/tmp_cf_merged.json")
            
            rm -f "$script_dir/tmp_cf_assets.json" "$script_dir/tmp_cf_formatted.json" "$script_dir/tmp_cf_merged.json"
            
            log_message "Successfully processed $record_count DNS records for Cloudflare zone $zone_name"
        else
            log_message "No DNS records found for Cloudflare zone $zone_name"
        fi
    done
    
    echo "✓ Successfully processed $processed_records Cloudflare records across $total_zones zones"
    
    # Save the Cloudflare assets
    echo "$cloudflare_assets" > "$cloudflare_file"
    
    log_message "Saved $(echo "$cloudflare_assets" | jq 'length') Cloudflare assets to $cloudflare_file"
}

# Check GoDaddy API quota limits
check_godaddy_quota() {
    log_message "Checking GoDaddy API quota limits..."
    
    # Use a HEAD request to check headers without consuming quota for a full request
    local headers
    headers=$(curl -s -I -X GET \
        -H "Authorization: sso-key $GODADDY_API_KEY:$GODADDY_API_SECRET" \
        -H "Accept: application/json" \
        "https://api.godaddy.com/v1/domains")
    
    # Check if headers were returned
    if [[ -z "$headers" ]]; then
        log_message "Error: Failed to get headers from GoDaddy API."
        return 1
    fi
    
    # Check for rate limit information
    local limit=$(echo "$headers" | grep -i "X-RateLimit-Limit" | cut -d':' -f2- | tr -d ' \r')
    local remaining=$(echo "$headers" | grep -i "X-RateLimit-Remaining" | cut -d':' -f2- | tr -d ' \r')
    local reset=$(echo "$headers" | grep -i "X-RateLimit-Reset" | cut -d':' -f2- | tr -d ' \r')
    
    # Display rate limit information
    log_message "GoDaddy API Rate Limit Information:"
    if [[ -n "$limit" ]]; then
        log_message "  - Rate Limit: $limit requests"
    else
        log_message "  - Rate Limit: Not provided"
    fi
    
    if [[ -n "$remaining" ]]; then
        log_message "  - Remaining: $remaining requests"
    else
        log_message "  - Remaining: Not provided"
    fi
    
    if [[ -n "$reset" ]]; then
        # Convert reset timestamp to human-readable date if it's a unix timestamp
        if [[ "$reset" =~ ^[0-9]+$ ]]; then
            local reset_date=$(date -r "$reset" 2>/dev/null || date -d "@$reset" 2>/dev/null || echo "$reset")
            log_message "  - Reset Time: $reset_date"
        else
            log_message "  - Reset Time: $reset"
        fi
    else
        log_message "  - Reset Time: Not provided"
    fi
    
    # Check for quota exceeded error in the response
    if echo "$headers" | grep -q "QUOTA_EXCEEDED"; then
        log_message "WARNING: GoDaddy API quota already exceeded."
        return 2
    fi
    
    # Also check a specific endpoint that might have different quotas
    local dns_headers
    dns_headers=$(curl -s -I -X GET \
        -H "Authorization: sso-key $GODADDY_API_KEY:$GODADDY_API_SECRET" \
        -H "Accept: application/json" \
        "https://api.godaddy.com/v1/domains/bertholdtypes.com/records")
    
    # Check if headers were returned
    if [[ -n "$dns_headers" ]]; then
        local dns_limit=$(echo "$dns_headers" | grep -i "X-RateLimit-Limit" | cut -d':' -f2- | tr -d ' \r')
        local dns_remaining=$(echo "$dns_headers" | grep -i "X-RateLimit-Remaining" | cut -d':' -f2- | tr -d ' \r')
        
        if [[ -n "$dns_limit" || -n "$dns_remaining" ]]; then
            log_message "DNS Records Endpoint Rate Limits:"
            [[ -n "$dns_limit" ]] && log_message "  - Rate Limit: $dns_limit requests"
            [[ -n "$dns_remaining" ]] && log_message "  - Remaining: $dns_remaining requests"
        fi
        
        # Check for quota exceeded in DNS endpoint specifically
        if echo "$dns_headers" | grep -q "QUOTA_EXCEEDED"; then
            log_message "WARNING: DNS records endpoint quota exceeded."
            return 3
        fi
    fi
    
    return 0
}

#####################
# Output Generation #
#####################

generate_asset_documentation() {
    log_message "Generating asset documentation..."
    
    # Merge GoDaddy and Cloudflare assets
    merge_json_files "$godaddy_file" "$cloudflare_file" "$merged_file"
    
    # Create a temporary file for processed assets
    tmp_processed=$(mktemp)
    
    # Process assets to preserve original discovery dates from history
    log_message "Processing discovery dates from history..."
    
    # Create a unique identifier for each asset (domain+name+type+data)
    # Then check if it exists in history to preserve its original discovery date
    jq --arg today "$today_date" --slurpfile history "$assets_history_file" '
        # Create a function to generate a unique ID for each record
        def asset_id(asset): asset.domain + "::" + asset.name + "::" + asset.type + "::" + asset.data;
        
        # Convert history to a map for easier lookup
        ($history[0] // []) as $old_records |
        ($old_records | map({key: asset_id(.), value: .discovery_date}) | from_entries) as $history_map |
        
        # For each current asset, check history and use original date if found
        map(. + {
            asset_id: asset_id(.),
            discovery_date: ($history_map[asset_id(.)] // $today)
        })
    ' "$merged_file" > "$tmp_processed"
    
    # Update the merged file with processed data
    mv "$tmp_processed" "$merged_file"
    
    # Update history file with current assets and their discovery dates
    jq --slurpfile current "$merged_file" '
        # Get existing assets from history
        . as $existing_history |
        
        # Get current assets
        ($current[0] // []) as $current_assets |
        
        # Combine them, ensuring no duplicates
        ($existing_history + $current_assets) |
        unique_by(.asset_id) |
        sort_by(.domain, .name)
    ' "$assets_history_file" > "$tmp_processed"
    
    mv "$tmp_processed" "$assets_history_file"
    log_message "Updated assets history file with $(jq length "$assets_history_file") unique records."
    
    # Check if GoDaddy assets are empty (likely due to quota being exceeded)
    local godaddy_count
    godaddy_count=$(jq 'length' "$godaddy_file")
    local godaddy_notice=""
    
    if [[ "$godaddy_count" -eq 0 ]]; then
        godaddy_notice="⚠️ **Note:** GoDaddy API quota has been exceeded. The results only contain Cloudflare assets. Try again later when the quota resets."
    fi
    
    # Generate markdown documentation
    {
        echo "# Organization Assets"
        echo ""
        echo "Last Updated: $today_date"
        echo ""
        if [[ -n "$godaddy_notice" ]]; then
            echo "$godaddy_notice"
            echo ""
        fi
        echo "## Summary"
        echo ""
        echo "- Total Assets: $(jq 'length' "$merged_file")"
        echo "- GoDaddy Assets: $(jq 'length' "$godaddy_file")"
        echo "- Cloudflare Assets: $(jq 'length' "$cloudflare_file")"
        echo ""
        echo "## Asset Details"
        echo ""
        echo "| Domain | Subdomain | Type | Data | Source | Discovery Date |"
        echo "|--------|-----------|------|------|--------|----------------|"
        jq -r '
            sort_by(.domain, .name)
            | .[]
            | "| " + (.domain // "N/A") + " | "
                  + (.name // "N/A") + " | "
                  + (.type // "N/A") + " | "
                  + (.data // "N/A") + " | "
                  + (.source // "N/A") + " | "
                  + (.discovery_date // "N/A") + " |"
        ' "$merged_file"
    } > "$markdown_file"
    
    # Generate HTML documentation with table filtering and responsive design
    {
        echo "<!DOCTYPE html>"
        echo "<html>"
        echo "<head>"
        echo "    <title>Organization Assets</title>"
        echo "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">"
        echo "    <style>"
        echo "        body { font-family: Arial, sans-serif; margin: 20px; max-width: 1200px; margin: 0 auto; padding: 20px; }"
        echo "        h1 { color: #333; }"
        echo "        .summary { background-color: #f5f5f5; padding: 20px; border-radius: 5px; margin-bottom: 30px; }"
        echo "        .warning { background-color: #fffce1; border-left: 4px solid #ffd600; padding: 10px 20px; margin-bottom: 20px; color: #846504; }"
        echo "        .warning strong { color: #846504; }"
        echo "        .info { background-color: #e8f4fd; border-left: 4px solid #0077cc; padding: 10px 20px; margin-bottom: 20px; color: #00508b; }"
        echo "        .info h3 { color: #00508b; margin-top: 0; }"
        echo "        .info ul { margin-left: 20px; padding-left: 0; }"
        echo "        .info li { margin-bottom: 5px; }"
        echo "        .table-container { overflow-x: auto; max-height: 80vh; }"
        echo "        table { width: 100%; border-collapse: collapse; margin-top: 20px; table-layout: fixed; }"
        echo "        th, td { border: 1px solid #ddd; padding: 12px; text-align: left; vertical-align: top; font-size: 13px; }"
        echo "        th { background-color: #4CAF50; color: white; cursor: pointer; position: sticky; top: 0; z-index: 10; }"
        echo "        th:hover { background-color: #3e8e41; }"
        echo "        tr:nth-child(even) { background-color: #f2f2f2; }"
        echo "        tr:hover { background-color: #ddd; }"
        echo "        .timestamp { color: #666; font-size: 0.9em; margin-bottom: 20px; }"
        echo "        .filter-row input { width: 100%; padding: 8px; box-sizing: border-box; }"
        echo "        .filter-controls { margin-bottom: 20px; }"
        echo "        .filter-controls button { padding: 8px 16px; margin-right: 10px; background-color: #4CAF50; color: white; border: none; border-radius: 4px; cursor: pointer; }"
        echo "        .filter-controls button:hover { background-color: #3e8e41; }"
        echo "        /* Column widths */"
        echo "        th:nth-child(1), td:nth-child(1) { width: 15%; } /* Domain */"
        echo "        th:nth-child(2), td:nth-child(2) { width: 15%; overflow-wrap: break-word; word-wrap: break-word; word-break: break-all; } /* Subdomain */"
        echo "        th:nth-child(3), td:nth-child(3) { width: 8%; } /* Type */"
        echo "        th:nth-child(4), td:nth-child(4) { width: 40%; overflow-wrap: break-word; word-wrap: break-word; word-break: break-all; hyphens: auto; max-width: 0; } /* Data */"
        echo "        th:nth-child(5), td:nth-child(5) { width: 10%; } /* Source */"
        echo "        th:nth-child(6), td:nth-child(6) { width: 12%; } /* Discovery Date */"
        echo "        /* Record-specific styling */"
        echo "        td.txt-data { font-family: monospace; font-size: 11px; white-space: pre-wrap; color: #333; }"
        echo "        td.cname-data { color: #0066cc; }"
        echo "        td.a-data { color: #009900; }"
        echo "        td.aaaa-data { color: #009900; }"
        echo "        td.mx-data { color: #cc6600; }"
        echo "        td.ns-data { color: #660066; }"
        echo "        td.spf-data { font-family: monospace; font-size: 11px; white-space: pre-wrap; color: #333; }"
        echo "        td.dkim-data { font-family: monospace; font-size: 11px; white-space: pre-wrap; color: #333; }"
        echo "        /* Toggle button styling */"
        echo "        .toggle-btn { margin-top: 5px; background-color: #f0f0f0; border: 1px solid #ccc; padding: 2px 5px; font-size: 11px; cursor: pointer; border-radius: 3px; }"
        echo "        .toggle-btn:hover { background-color: #e0e0e0; }"
        echo "        .collapsed-content { word-break: break-all; }"
        echo "        .full-content { word-break: break-all; padding: 3px; background-color: #f9f9f9; border: 1px solid #eee; border-radius: 3px; margin-top: 3px; font-size: 11px; max-height: 300px; overflow-y: auto; }"
        echo "        /* Responsive design */"
        echo "        @media screen and (max-width: 768px) {"
        echo "            body { margin: 10px; padding: 10px; }"
        echo "            .filter-controls button { width: 100%; margin-bottom: 10px; }"
        echo "            th, td { padding: 8px; font-size: 14px; }"
        echo "        }"
        echo "    </style>"
        echo "</head>"
        echo "<body>"
        echo "    <h1>Organization Assets</h1>"
        echo "    <div class='timestamp'>Last Updated: $today_date</div>"
        if [[ -n "$godaddy_notice" ]]; then
            echo "    <div class='warning'><strong>Warning:</strong> GoDaddy API quota has been exceeded. The results only contain Cloudflare assets. Try again later when the quota resets.</div>"
            
            # Add explanation about GoDaddy API quotas
            echo "    <div class='info'>"
            echo "        <h3>About GoDaddy API Quotas</h3>"
            echo "        <p>The GoDaddy API has limited quota allowances:</p>"
            echo "        <ul>"
            echo "            <li><strong>Monthly Quota:</strong> GoDaddy limits the number of API calls per month (typically 1,000-5,000 depending on your plan).</li>"
            echo "            <li><strong>Rate Limits:</strong> GoDaddy also limits the rate of API calls (typically 60 per minute).</li>"
            echo "            <li><strong>Reset Time:</strong> Monthly quotas typically reset at the beginning of each calendar month.</li>"
            echo "        </ul>"
            echo "        <p>If you need higher quotas, consider contacting GoDaddy to upgrade your API plan.</p>"
            echo "    </div>"
        fi
        echo "    <div class='summary'>"
        echo "        <h2>Summary</h2>"
        echo "        <p>Total Assets: $(jq 'length' "$merged_file")</p>"
        echo "        <p>GoDaddy Assets: $(jq 'length' "$godaddy_file")</p>"
        echo "        <p>Cloudflare Assets: $(jq 'length' "$cloudflare_file")</p>"
        echo "    </div>"
        echo "    <div class='filter-controls'>"
        echo "        <button onclick='resetFilters()'>Reset Filters</button>"
        echo "        <button onclick='exportToCSV()'>Export to CSV</button>"
        echo "    </div>"
        echo "    <h2>Asset Details</h2>"
        echo "    <div class='table-container'>"
        echo "        <table id='assetsTable'>"
        echo "            <thead>"
        echo "                <tr>"
        echo "                    <th onclick='sortTable(0)'>Domain</th>"
        echo "                    <th onclick='sortTable(1)'>Subdomain</th>"
        echo "                    <th onclick='sortTable(2)'>Type</th>"
        echo "                    <th onclick='sortTable(3)'>Data</th>"
        echo "                    <th onclick='sortTable(4)'>Source</th>"
        echo "                    <th onclick='sortTable(5)'>Discovery Date</th>"
        echo "                </tr>"
        echo "                <tr class='filter-row'>"
        echo "                    <td><input type='text' onkeyup='filterTable()' placeholder='Filter domain...'></td>"
        echo "                    <td><input type='text' onkeyup='filterTable()' placeholder='Filter subdomain...'></td>"
        echo "                    <td><input type='text' onkeyup='filterTable()' placeholder='Filter type...'></td>"
        echo "                    <td><input type='text' onkeyup='filterTable()' placeholder='Filter data...'></td>"
        echo "                    <td><input type='text' onkeyup='filterTable()' placeholder='Filter source...'></td>"
        echo "                    <td><input type='text' onkeyup='filterTable()' placeholder='Filter date...'></td>"
        echo "                </tr>"
        echo "            </thead>"
        echo "            <tbody>"
        jq -r '
            sort_by(.domain, .name)
            | .[]
            | "            <tr>\n"
                  + "                <td>" + (.domain // "N/A") + "</td>\n"
                  + "                <td>" + (.name // "N/A") + "</td>\n"
                  + "                <td>" + (.type // "N/A") + "</td>\n"
                  + "                <td class=\"" + (.type | ascii_downcase) + "-data\">" + (.data // "N/A") + "</td>\n"
                  + "                <td>" + (.source // "N/A") + "</td>\n"
                  + "                <td>" + (.discovery_date // "N/A") + "</td>\n"
                  + "            </tr>"
        ' "$merged_file"
        echo "            </tbody>"
        echo "        </table>"
        echo "    </div>"
        echo "    <script>"
        echo "        // Function to process long text content when page loads"
        echo "        window.onload = function() {"
        echo "            processTxtRecords();"
        echo "            // After initial load, sort by domain name"
        echo "            sortTable(0);"
        echo "        };"
        
        echo "        function processTxtRecords() {"
        echo "            // Get all cells with txt-data class or other types with long data"
        echo "            const longDataCells = document.querySelectorAll('td.txt-data, td.dkim-data, td.spf-data');"
        echo "            longDataCells.forEach(cell => {"
        echo "                const content = cell.textContent;"
        echo "                // If content is longer than 60 characters, make it collapsible"
        echo "                if (content.length > 60) {"
        echo "                    const shortContent = content.substring(0, 60) + '...';"
        echo "                    cell.innerHTML = \`"
        echo "                        <div class='collapsed-content'>\${shortContent}</div>"
        echo "                        <div class='full-content' style='display:none'>\${content}</div>"
        echo "                        <button class='toggle-btn' onclick='toggleContent(this)'>Show More</button>"
        echo "                    \`;"
        echo "                }"
        echo "            });"
        echo ""
        echo "            // Also process any CNAME data that's long"
        echo "            const cnameCells = document.querySelectorAll('td.cname-data, td.mx-data');"
        echo "            cnameCells.forEach(cell => {"
        echo "                const content = cell.textContent;"
        echo "                if (content.length > 40) {"
        echo "                    const shortContent = content.substring(0, 40) + '...';"
        echo "                    cell.innerHTML = \`"
        echo "                        <div class='collapsed-content'>\${shortContent}</div>"
        echo "                        <div class='full-content' style='display:none'>\${content}</div>"
        echo "                        <button class='toggle-btn' onclick='toggleContent(this)'>Show More</button>"
        echo "                    \`;"
        echo "                }"
        echo "            });"
        echo ""
        echo "            // Process long subdomains"
        echo "            const subdomainCells = document.querySelectorAll('tbody tr td:nth-child(2)');"
        echo "            subdomainCells.forEach(cell => {"
        echo "                const content = cell.textContent;"
        echo "                if (content.length > 30) {"
        echo "                    const shortContent = content.substring(0, 30) + '...';"
        echo "                    cell.innerHTML = \`"
        echo "                        <div class='collapsed-content'>\${shortContent}</div>"
        echo "                        <div class='full-content' style='display:none'>\${content}</div>"
        echo "                        <button class='toggle-btn' onclick='toggleContent(this)'>Show More</button>"
        echo "                    \`;"
        echo "                }"
        echo "            });"
        echo "        }"
        
        echo "        function toggleContent(btn) {"
        echo "            const cell = btn.parentElement;"
        echo "            const collapsedDiv = cell.querySelector('.collapsed-content');"
        echo "            const fullDiv = cell.querySelector('.full-content');"
        
        echo "            if (collapsedDiv.style.display === 'none') {"
        echo "                collapsedDiv.style.display = 'block';"
        echo "                fullDiv.style.display = 'none';"
        echo "                btn.textContent = 'Show More';"
        echo "            } else {"
        echo "                collapsedDiv.style.display = 'none';"
        echo "                fullDiv.style.display = 'block';"
        echo "                btn.textContent = 'Show Less';"
        echo "            }"
        echo "        }"

        echo "        function filterTable() {"
        echo "            const table = document.getElementById('assetsTable');"
        echo "            const rows = table.getElementsByTagName('tr');"
        echo "            const filters = document.querySelectorAll('.filter-row input');"
        echo ""
        echo "            // Start from 2 to skip header and filter rows"
        echo "            for (let i = 2; i < rows.length; i++) {"
        echo "                let show = true;"
        echo "                const cells = rows[i].getElementsByTagName('td');"
        echo ""
        echo "                for (let j = 0; j < filters.length; j++) {"
        echo "                    const filter = filters[j].value.toUpperCase();"
        echo "                    if (filter && cells[j].textContent.toUpperCase().indexOf(filter) === -1) {"
        echo "                        show = false;"
        echo "                        break;"
        echo "                    }"
        echo "                }"
        echo ""
        echo "                rows[i].style.display = show ? '' : 'none';"
        echo "            }"
        echo "        }"
        echo ""
        echo "        function resetFilters() {"
        echo "            const filters = document.querySelectorAll('.filter-row input');"
        echo "            filters.forEach(filter => filter.value = '');"
        echo "            filterTable();"
        echo "        }"
        echo ""
        echo "        function sortTable(n) {"
        echo "            const table = document.getElementById('assetsTable');"
        echo "            let switching = true;"
        echo "            let dir = 'asc';"
        echo "            let switchcount = 0;"
        echo ""
        echo "            while (switching) {"
        echo "                switching = false;"
        echo "                const rows = table.rows;"
        echo ""
        echo "                for (let i = 2; i < (rows.length - 1); i++) {"
        echo "                    let shouldSwitch = false;"
        echo "                    const x = rows[i].getElementsByTagName('td')[n];"
        echo "                    const y = rows[i + 1].getElementsByTagName('td')[n];"
        echo ""
        echo "                    if (dir === 'asc') {"
        echo "                        if (x.innerHTML.toLowerCase() > y.innerHTML.toLowerCase()) {"
        echo "                            shouldSwitch = true;"
        echo "                            break;"
        echo "                        }"
        echo "                    } else if (dir === 'desc') {"
        echo "                        if (x.innerHTML.toLowerCase() < y.innerHTML.toLowerCase()) {"
        echo "                            shouldSwitch = true;"
        echo "                            break;"
        echo "                        }"
        echo "                    }"
        echo ""
        echo "                    if (shouldSwitch) {"
        echo "                        rows[i].parentNode.insertBefore(rows[i + 1], rows[i]);"
        echo "                        switching = true;"
        echo "                        switchcount++;"
        echo "                    }"
        echo "                }"
        echo ""
        echo "                if (switchcount === 0 && dir === 'asc') {"
        echo "                    dir = 'desc';"
        echo "                    switching = true;"
        echo "                }"
        echo "            }"
        echo "        }"
        echo ""
        echo "        function exportToCSV() {"
        echo "            const table = document.getElementById('assetsTable');"
        echo "            let csv = [];"
        echo "            const rows = table.querySelectorAll('tr');"
        echo ""
        echo "            for (let i = 0; i < rows.length; i++) {"
        echo "                if (i === 1) continue; // Skip the filter row"
        echo "                if (rows[i].style.display === 'none') continue; // Skip filtered out rows"
        echo ""
        echo "                const row = [];"
        echo "                const cols = rows[i].querySelectorAll('td, th');"
        echo ""
        echo "                for (let j = 0; j < cols.length; j++) {"
        echo "                    // Get the text content, handling header cells"
        echo "                    let text = cols[j].textContent || cols[j].innerText;"
        echo "                    // Replace commas and quotes"
        echo "                    text = text.replace(/\"/g, '\"\"');"
        echo "                    row.push('\"' + text + '\"');"
        echo "                }"
        echo "                csv.push(row.join(','));"
        echo "            }"
        echo ""
        echo "            const csvStr = csv.join('\\n');"
        echo "            const blob = new Blob([csvStr], { type: 'text/csv;charset=utf-8;' });"
        echo "            const link = document.createElement('a');"
        echo "            const url = URL.createObjectURL(blob);"
        echo ""
        echo "            link.setAttribute('href', url);"
        echo "            link.setAttribute('download', 'org_assets_' + new Date().toISOString().slice(0, 10) + '.csv');"
        echo "            link.style.visibility = 'hidden';"
        echo "            document.body.appendChild(link);"
        echo "            link.click();"
        echo "            document.body.removeChild(link);"
        echo "        }"
        echo "    </script>"
        echo "</body>"
        echo "</html>"
    } > "$html_file"
}

#####################
# Main Execution    #
#####################

# Initialize JSON files
echo "[]" > "$godaddy_file"
echo "[]" > "$cloudflare_file"
echo "[]" > "$merged_file"

# Check API connectivity before proceeding
if ! check_api_connectivity; then
    log_message "Error: API connectivity check failed. Exiting."
    exit 1
fi

# Check GoDaddy API quota limits
if ! check_godaddy_quota; then
    log_message "Error: GoDaddy API quota check failed. Exiting."
    exit 1
fi

# Fetch assets based on selected options
if [[ "$RUN_GODADDY" == "true" ]]; then
    fetch_godaddy_assets
fi

if [[ "$RUN_CLOUDFLARE" == "true" ]]; then
    fetch_cloudflare_assets
fi

# Generate documentation
generate_asset_documentation

# Final summary
log_message "Script Execution Completed: $(date)"
log_message ""
log_message "Output Files:"
log_message "- GoDaddy Assets: $godaddy_file"
log_message "- Cloudflare Assets: $cloudflare_file"
log_message "- Merged Assets: $merged_file"
log_message "- Asset Documentation (Markdown): $markdown_file"
log_message "- Asset Documentation (HTML): $html_file"